diff --git a/cudaCanny/cudaCanny/canny.cu b/cudaCanny/cudaCanny/canny.cu
index e059ad2..70342fc 100644
--- a/cudaCanny/cudaCanny/canny.cu
+++ b/cudaCanny/cudaCanny/canny.cu
@@ -6,7 +6,7 @@
 #include "device_launch_parameters.h"
 #include <math.h>
 
-void apply_canny(uint8_t* final_pixels, const uint8_t* ori_pixels, int weak_threshold, int strong_threshold, int image_width, int image_height, int thd_per_blk) {
+void apply_canny(uint8_t* final_pixels, uint8_t* week_pixels, const uint8_t* ori_pixels, int weak_threshold, int strong_threshold, int image_width, int image_height, int thd_per_blk) {
 
 	// gaussian kernel
 	const double gaussian_kernel[9] = {
@@ -14,43 +14,42 @@ void apply_canny(uint8_t* final_pixels, const uint8_t* ori_pixels, int weak_thre
 		2,4,2,
 		1,2,1
 	};
-	const int8_t sobel_kernel_x[] = {   -1, 0, 1,
+	const int8_t sobel_kernel_x[] =    {   -1, 0, 1,
 										-2, 0, 2,
 										-1, 0, 1 };
-	const int8_t sobel_kernel_y[] = {    1, 2, 1,
+	const int8_t sobel_kernel_y[] =    {    1, 2, 1,
 										 0, 0, 0,
 										-1,-2,-1 };
 	/* kernel execution configuration parameters */
-	const int num_blks = (image_height * image_width) / thd_per_blk;
+	const int num_blks = (image_height * image_width + thd_per_blk - 1) / thd_per_blk;
 	const int grid = 0;
 
 	/* device buffers */
-	uint8_t* in, * out;
+	uint8_t* in, * out, * out_week;
 	double* gradient_pixels;
 	double* max_pixels;
 	uint8_t* segment_pixels;
 	double* gaussian_kernel_gpu;
 	int8_t* sobel_kernel_x_gpu;
 	int8_t* sobel_kernel_y_gpu;
-	uint8_t* final_result;
 
 	float elapsed = 0;
 	cudaEvent_t start, stop;
 	cudaEventCreate(&start);
 	cudaEventCreate(&stop);
-	cudaEventRecord(start, 0);  //start timer
 
 	/* allocate device memory */
 	cudaMalloc((void**)&in, sizeof(uint8_t) * image_height * image_width);
 	cudaMalloc((void**)&out, sizeof(uint8_t) * image_height * image_width);
 	cudaMalloc((void**)&gradient_pixels, sizeof(double) * image_height * image_width);
-	cudaMalloc((void**)&final_result, sizeof(uint8_t) * image_height * image_width);
+	cudaMalloc((void**)&out_week, sizeof(uint8_t) * image_height * image_width);
 	cudaMalloc((void**)&max_pixels, sizeof(double) * image_height * image_width);
 	cudaMalloc((void**)&segment_pixels, sizeof(uint8_t) * image_height * image_width);
 	cudaMalloc((void**)&gaussian_kernel_gpu, sizeof(double) * KERNEL_SIZE * KERNEL_SIZE);
 	cudaMalloc((void**)&sobel_kernel_x_gpu, sizeof(int8_t) * 3 * 3);
 	cudaMalloc((void**)&sobel_kernel_y_gpu, sizeof(int8_t) * 3 * 3);
 
+	cudaEventRecord(start, 0);  //start timer
 	/* data transfer image pixels to device */
 	cudaMemcpy(in, ori_pixels, image_height * image_width * sizeof(uint8_t), cudaMemcpyHostToDevice);
 	cudaMemcpy(gaussian_kernel_gpu, gaussian_kernel, sizeof(double) * KERNEL_SIZE * KERNEL_SIZE, cudaMemcpyHostToDevice);
@@ -71,16 +70,21 @@ void apply_canny(uint8_t* final_pixels, const uint8_t* ori_pixels, int weak_thre
 	// 3. local maxima: non maxima suppression
 	apply_non_max_suppression << <num_blks, thd_per_blk, grid, stream >> > (max_pixels, gradient_pixels, segment_pixels, image_width, image_height);
 	// 4. double threshold
-	apply_double_threshold << <num_blks, thd_per_blk, grid, stream >> > (out,max_pixels,strong_threshold,weak_threshold, image_width, image_height);
-	// 5. edges with hysteresis
-	cudaMemcpy(final_result, out, image_height * image_width * sizeof(uint8_t), cudaMemcpyDeviceToDevice);
-	apply_edge_hysteresis << <num_blks, thd_per_blk, grid, stream >> > (final_result, out, image_width, image_height);
+	apply_double_threshold << <num_blks, thd_per_blk, grid, stream >> > (out,out_week,max_pixels,strong_threshold,weak_threshold, image_width, image_height);
+	// // 5. edges with hysteresis
+	// cudaMemcpy(out_week, out, image_height * image_width * sizeof(uint8_t), cudaMemcpyDeviceToDevice);
+	// apply_edge_hysteresis << <num_blks, thd_per_blk, grid, stream >> > (out_week, out, image_width, image_height);
 
 	/* wait for everything to finish */
 	cudaDeviceSynchronize();
 
 	/* copy result back to the host */
-	cudaMemcpy(final_pixels, final_result, image_width * image_height * sizeof(uint8_t), cudaMemcpyDeviceToHost);
+	cudaMemcpy(final_pixels, out, image_width * image_height * sizeof(uint8_t), cudaMemcpyDeviceToHost);
+
+	cudaMemcpy(week_pixels, out_week, image_width * image_height * sizeof(uint8_t), cudaMemcpyDeviceToHost);
+
+	cudaEventRecord(stop, 0); //end timer
+	cudaEventSynchronize(stop);
 
 	cudaFree(in);
 	cudaFree(out);
@@ -90,10 +94,8 @@ void apply_canny(uint8_t* final_pixels, const uint8_t* ori_pixels, int weak_thre
 	cudaFree(gaussian_kernel_gpu);
 	cudaFree(sobel_kernel_x_gpu);
 	cudaFree(sobel_kernel_y_gpu);
-	cudaFree(final_result);
+	cudaFree(out_week);
 
-	cudaEventRecord(stop, 0); //end timer
-	cudaEventSynchronize(stop);
 	cudaEventElapsedTime(&elapsed, start, stop);
 	cudaEventDestroy(start);
 	cudaEventDestroy(stop);
@@ -108,23 +110,30 @@ __global__ void apply_gaussian_filter(uint8_t* out_pixels, const uint8_t* in_pix
 	if (!(pixNum >= 0 && pixNum < image_height * image_width))
 		return;
 
+	int x = pixNum % image_width;
+	int y = pixNum / image_width;
+
 	//Apply Kernel to image
 	double kernelSum = 0;
 	double pixelVal = 0;
 	for (int i = 0; i < KERNEL_SIZE; ++i) {
 		for (int j = 0; j < KERNEL_SIZE; ++j) {
 			//check edge cases, if within bounds, apply filter
-			if (((pixNum + ((i - offset_xy) * image_width) + j - offset_xy) >= 0)
-				&& ((pixNum + ((i - offset_xy) * image_width) + j - offset_xy) <= image_height * image_width - 1)
-				&& (((pixNum % image_width) + j - offset_xy) >= 0)
-				&& (((pixNum % image_width) + j - offset_xy) <= (image_width - 1))) {
-
-				pixelVal += gaussian_kernel[i * KERNEL_SIZE + j] * in_pixels[pixNum + ((i - offset_xy) * image_width) + j - offset_xy];
-				kernelSum += gaussian_kernel[i * KERNEL_SIZE + j];
-			}
+            int kernel_x = x + j - offset_xy;
+            int kernel_y = y + i - offset_xy;
+            if ( kernel_x < 0 )
+                kernel_x = 0;
+            if ( kernel_x >= image_width )
+                kernel_x = image_width - 1;
+            if ( kernel_y < 0 )
+                kernel_y = 0;
+            if ( kernel_y >= image_height )
+                kernel_y = image_height - 1;
+            pixelVal += gaussian_kernel[i * KERNEL_SIZE + j] * in_pixels[kernel_y * image_width + kernel_x];
+			kernelSum += gaussian_kernel[i * KERNEL_SIZE + j];
 		}
 	}
-	out_pixels[pixNum] = (uint8_t)(pixelVal / kernelSum);
+	out_pixels[pixNum] = (uint8_t)(pixelVal / kernelSum + 0.5);
 	
 }
 __global__ void apply_sobel_filter(double* gradient_pixels, uint8_t* segment_pixels, const uint8_t* in_pixels, int image_width, int image_height, int8_t* sobel_kernel_x, int8_t* sobel_kernel_y ) {
@@ -135,25 +144,35 @@ __global__ void apply_sobel_filter(double* gradient_pixels, uint8_t* segment_pix
 	int x = pixNum % image_width;
 	int y = pixNum / image_width;
 	int offset_xy = 1;  // 3x3
-	if (x < offset_xy || x >= image_width - offset_xy || y < offset_xy || y >= image_height - offset_xy)
-		return;
+	// if (x < offset_xy || x >= image_width - offset_xy || y < offset_xy || y >= image_height - offset_xy)
+	// 	return;
 	double convolve_X = 0.0;
 	double convolve_Y = 0.0;
 	int k = 0;
 	int src_pos = x + (y * image_width);
 
-	for (int ky = -offset_xy; ky <= offset_xy; ky++) {
-		for (int kx = -offset_xy; kx <= offset_xy; kx++) {
-			convolve_X += in_pixels[src_pos + (kx + (ky * image_width))] * sobel_kernel_x[k];
-			convolve_Y += in_pixels[src_pos + (kx + (ky * image_width))] * sobel_kernel_y[k];
-			k++;
+	for (int i = -offset_xy; i <= offset_xy; i++) {
+		for (int j = -offset_xy; j <= offset_xy; j++) {
+            int kernel_x = x + j;
+            int kernel_y = y + i;
+            if ( kernel_x < 0 )
+                kernel_x = 0;
+            if ( kernel_x >= image_width )
+                kernel_x = image_width - 1;
+            if ( kernel_y < 0 )
+                kernel_y = 0;
+            if ( kernel_y >= image_height )
+                kernel_y = image_height - 1;
+            convolve_X += in_pixels[kernel_y * image_width + kernel_x] * sobel_kernel_x[k];
+			convolve_Y += in_pixels[kernel_y * image_width + kernel_x] * sobel_kernel_y[k];
+            k++;
 		}
 	}
 
 	// gradient hypot & direction
 	int segment = 0;
 
-	if (convolve_X == 0.0 || convolve_Y == 0.0) {
+	if (convolve_X == 0.0 && convolve_Y == 0.0) {
 		gradient_pixels[src_pos] = 0;
 	}
 	else {
@@ -177,21 +196,27 @@ __global__ void apply_non_max_suppression(double* max_pixels, double* gradient_p
 	int pos = blockIdx.x * blockDim.x + threadIdx.x;
 	if (!(pos >= 0 && pos < image_height * image_width))
 		return;
+	int x = pos % image_width;
+	int y = pos / image_width;
 	switch (segment_pixels[pos]) {
 	case 1:
-		if (segment_pixels[pos - 1] >= gradient_pixels[pos] || gradient_pixels[pos + 1] > gradient_pixels[pos])
+		if ( (gradient_pixels[pos - 1] >= gradient_pixels[pos] && x > 0) || 
+                (gradient_pixels[pos + 1] > gradient_pixels[pos] && x < image_width - 1) )
 			max_pixels[pos] = 0;
 		break;
 	case 2:
-		if (gradient_pixels[pos - (image_width - 1)] >= gradient_pixels[pos] || gradient_pixels[pos + (image_width - 1)] > gradient_pixels[pos])
+		if ( (gradient_pixels[pos - image_width + 1] >= gradient_pixels[pos] && x < image_width - 1 && y > 0 )|| 
+                (gradient_pixels[pos + image_width - 1] >= gradient_pixels[pos] && y < image_height - 1 && x > 0) )
 			max_pixels[pos] = 0;
 		break;
 	case 3:
-		if (gradient_pixels[pos - (image_width)] >= gradient_pixels[pos] || gradient_pixels[pos + (image_width)] > gradient_pixels[pos])
+		if ( (gradient_pixels[pos - image_width] >= gradient_pixels[pos] && y > 0) || 
+                (gradient_pixels[pos + image_width] > gradient_pixels[pos] && y < image_height - 1) )
 			max_pixels[pos] = 0;
 		break;
 	case 4:
-		if (gradient_pixels[pos - (image_width + 1)] >= gradient_pixels[pos] || gradient_pixels[pos + (image_width + 1)] > gradient_pixels[pos])
+		if ( (gradient_pixels[pos - image_width - 1] >= gradient_pixels[pos] &&  x > 0 && y > 0) || 
+                (gradient_pixels[pos + (image_width + 1)] >= gradient_pixels[pos] && x < image_width - 1 && y < image_height - 1) )
 			max_pixels[pos] = 0;
 		break;
 	default:
@@ -200,30 +225,33 @@ __global__ void apply_non_max_suppression(double* max_pixels, double* gradient_p
 	}
 
 }
-__global__ void apply_double_threshold(uint8_t* out, double* max_pixels, int strong_threshold, int weak_threshold, int image_width, int image_height) {
+__global__ void apply_double_threshold(uint8_t* out, uint8_t* out_week, double* max_pixels, int strong_threshold, int weak_threshold, int image_width, int image_height) {
 	int pos = blockIdx.x * blockDim.x + threadIdx.x;
 	if (!(pos >= 0 && pos < image_height * image_width))
 		return;
 	if (max_pixels[pos] > strong_threshold)
 		out[pos] = 255;      //absolutely edge
 	else if (max_pixels[pos] > weak_threshold)
-		out[pos] = 100;      //potential edge
+    {
+        out[pos] = 0;
+        out_week[pos] = 1;      //potential edge
+    }
 	else
 		out[pos] = 0;       //absolutely not edge
 }
-__global__ void apply_edge_hysteresis(uint8_t* out, uint8_t* in, int image_width, int image_height) {
-	int pos = blockIdx.x * blockDim.x + threadIdx.x;
-	if (!(pos >= 0 && pos < image_height * image_width))
-		return;
-	if (in[pos] == 100) {
-		if (in[pos - 1] == 255 || in[pos + 1] == 255 ||
-			in[pos - image_width] == 255 || in[pos + image_width] == 255 ||
-			in[pos - image_width - 1] == 255 || in[pos - image_width + 1] == 255 ||
-			in[pos + image_width - 1] == 255 || in[pos + image_width + 1] == 255)
-			out[pos] = 255;
-		else
-			out[pos] = 0;
-	}
+// __global__ void apply_edge_hysteresis(uint8_t* out, uint8_t* in, int image_width, int image_height) {
+// 	int pos = blockIdx.x * blockDim.x + threadIdx.x;
+// 	if (!(pos >= 0 && pos < image_height * image_width))
+// 		return;
+// 	if (in[pos] == 100) {
+// 		if (in[pos - 1] == 255 || in[pos + 1] == 255 ||
+// 			in[pos - image_width] == 255 || in[pos + image_width] == 255 ||
+// 			in[pos - image_width - 1] == 255 || in[pos - image_width + 1] == 255 ||
+// 			in[pos + image_width - 1] == 255 || in[pos + image_width + 1] == 255)
+// 			out[pos] = 255;
+// 		else
+// 			out[pos] = 0;
+// 	}
 
-}
+// }
 
diff --git a/cudaCanny/cudaCanny/canny.h b/cudaCanny/cudaCanny/canny.h
index 54926fe..4b81dfa 100644
--- a/cudaCanny/cudaCanny/canny.h
+++ b/cudaCanny/cudaCanny/canny.h
@@ -1,11 +1,11 @@
 #include <iostream>
 #include "cuda_runtime.h"
 
-void apply_canny(uint8_t* dst, const uint8_t* src, int weak_threshold, int strong_threshold, int w_, int h_, int thd_per_blk);
+void apply_canny(uint8_t* dst, uint8_t* dst_week, const uint8_t* src, int weak_threshold, int strong_threshold, int w_, int h_, int thd_per_blk);
 __global__ void apply_gaussian_filter(uint8_t* dst, const uint8_t* src, int image_width, int image_height, double* d_blur_kernel);
 __global__ void apply_sobel_filter(double* out_gradient, uint8_t* out_segment, const uint8_t* in, int image_width, int image_height, int8_t* sobel_kernel_x, int8_t* sobel_kernel_y);
 __global__ void apply_non_max_suppression(double* out_M, double* in_gradient, uint8_t* in_segment, int image_width, int image_height);
-__global__ void apply_double_threshold(uint8_t* dst, double* M_, int strong_threshold, int weak_threshold, int image_width, int image_height);
-__global__ void apply_edge_hysteresis(uint8_t* out, uint8_t* in, int image_width, int image_height);
+__global__ void apply_double_threshold(uint8_t* dst, uint8_t* dst_week, double* M_, int strong_threshold, int weak_threshold, int image_width, int image_height);
+// __global__ void apply_edge_hysteresis(uint8_t* out, int* in, int image_width, int image_height);